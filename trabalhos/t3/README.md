# T3: Profiling de algoritmos de machine learning do Weka / wekaPython


## Motiva√ß√£o

Weka √© uma ferramenta desenvolvida na Universidade de Waikato, na Nova Zel√¢ndia. √â uma ferramenta consolidada e muito popular na √°rea de data mining, oferecendo diversos algoritmos de machine learning e facilidades para aplic√°-los via interface gr√°fica ou via c√≥digo Java.

Weka permite a instala√ß√£o de pacotes que estendem suas funcionalidades. Um desses pacotes √© o wekaPython, que habilita o Weka a invocar bibliotecas em Python, tais como scikit-learn. Com isso, √© poss√≠vel combinar facilidades do Weka com estas bibliotecas.

Uma execu√ß√£o t√≠pica do Weka compreende a carga de um dataset e seu processamento com um algoritmo escolhido. 
Muitos algoritmos podem exigir um tempo de execu√ß√£o significativo para datasets com muitas inst√¢ncias e atributos.
Mas como esse tempo de execu√ß√£o se divide entre as diversas partes do Weka e das bibliotecas em Python? Ser√° que √© poss√≠vel fazer profiling disso? 


## Prepara√ß√£o

1. Instale o Weka, o wekaPython e suas depend√™ncias. Isso est√° descrito nos passos 1 a 4 da se√ß√£o de Prepara√ß√£o/Instala√ß√£o em https://github.com/cassales/progpar-2022-profiling

2. Baixe o dataset GMSC indicado em: https://github.com/cassales/progpar-2022-profiling#datasets Ap√≥s descompact√°-lo, vai ser gerado um arquivo GMSC.arff. Verifique a localiza√ß√£o (path) para esse arquivo, pois vai ser necess√°rio no passo seguinte.

3. Execute o Weka com o algoritmo XGBoost para o dataset GMSC:
   ```
   $ cd weka-3-8-6
   $ ./weka.sh -memory 32g -main weka.Run weka.classifiers.sklearn.ScikitLearnClassifier -learner XGBClassifier -parameters "tree_method=\"hist\",n_jobs=1" -t ~/Downloads/datasets/GMSC.arff -py-command python
   ```
   No comando acima, altere `~/Downloads/datasets` para a localiza√ß√£o do arquivo GMSC.arff em seu computador.


4. Avise a professora quando terminar esses passos, para "desbloquear" os passos seguintes. üòÉ



# Desenvolvimento


Vamos realizar execu√ß√µes com diferentes algoritmos (XGBoost, RandomForest e LinearRegression) e datasets, em diferentes computadores. Tamb√©m vamos variar o par√¢metro `n_jobs` entre diferentes rodadas, para ativar a execu√ß√£o paralela dos algoritmos.
As execu√ß√µes ser√£o feitas com e sem coleta de dados para profiling, que ser√° feito combinando as ferramentas JFR (Java Flight Recorder) e JMC (Java Mission Control).

Para facilitar as execu√ß√µes, √© fornecido um script que automatiza o processo, lendo as vari√°veis dos experimentos de um arquivo e salvando todos os resultados em uma pasta, de forma padronizada.

Para realizar as execu√ß√µes, fa√ßa o seguinte:

1. Confira se voc√™ consegue executar o Weka via `weka.sh`, conforme instru√ß√µes da se√ß√£o de Prepara√ß√£o. 

2. Baixe uma vers√£o alterada do `weka.sh`, que tem uma op√ß√£o para ativar a coleta de dados com JFR. Fa√ßa isso dentro da pasta do Weka. Por exemplo:
   ```
   cd ~/Downloads/weka-3-8-6
   wget ...
   ```

3. Em uma pasta separada, baixe o script que automatiza as rodadas, o arquivo com as vari√°veis dos experimentos e um arquivo com configura√ß√µes para o JFR:
   ```
   wget ...
   wget ...
   wget ...
   ```
   **Aten√ß√£o!** Estes arquivos devem ficar todos na mesma pasta.

4. Abra o script [run-exps.sh](run-exps.sh) e ajuste as vari√°veis com a localiza√ß√£o do Weka e dos datasets. Certifique-se de que voc√™ tenha datasets na pasta indicada.

5. Abra o arquivo [exp-vars.csv](exp-vars.csv) e veja que s√£o fornecidos alguns exemplos de par√¢metros para as rodadas. Para iniciar, √© conveniente executar somente um caso de teste. Isso pode ser feito removendo os outros casos, mantendo somente as 2 primeiras linhas do arquivo (a primeira cont√©m um cabe√ßalho e a segunda cont√©m par√¢metros para a execu√ß√£o).

6. Para executar o script que automatiza as rodadas, v√° para a pasta que cont√©m o script e digite:
   ```
   bash run-exps.sh
   ```
   Se tudo der certo, ser√° criada uma pasta de resultados contendo alguns arquivos:
   - times.csv: cont√©m tempos de execu√ß√£o de cada caso
   - arquivos com extens√£o .txt: cont√™m sa√≠das do Weka para cada caso
   - arquivos com extens√£o .jfr: cont√™m informa√ß√µes para profiling e podem ser examinados usando o JMC obtido em: https://www.azul.com/products/components/zulu-mission-control/

7. Depois de executar o script para um caso, voc√™ pode acrescentar outros algoritmos, datasets e valores de `n_jobs` em [exp-vars.csv](exp-vars.csv). 

8. Quando tiver realizado os experimentos, entregue todos os arquivos com resultados em https://classroom.github.com/a/SRjt-pEL e preencha o relat√≥rio compartilhado (link para Google Docs ser√° enviado no Discord).




# Quest√µes

1. Qual o efeito do par√¢metro `n_jobs` sobre o tempo de execu√ß√£o de cada algoritmo e dataset? 

2. Usando o JMC, como o tempo de execu√ß√£o se divide entre os diversos m√©todos invocados em cada caso? (veja Method Profiling no JMC)
